# These three lines define the names of our sources, channels, and sinks 
    # that are inside of the agent.
    # Each command always starts with the name of the agent.
    agent.sources = kafkaSource
    agent.channels = channel
    agent.sinks = sinkToHdfs
    # We are going to now start configuring the source.
    # Commands still start with the agent name and then 
    # .<component> in this case 'sources' then the name of the
    # component you are configuring
    # Here we define the type of source as a kafka source
    agent.sources.kafkaSource.type = org.apache.flume.source.kafka.KafkaSource
    # This tells the kafka source how to connnect to zookeeper 
    # just like we did in the kafka consumer
    # agent.sources.kafkaSource.bootstrap.servers = localhost:2181
    agent.sources.kafkaSource.zookeeperConnect = localhost:2181
    # Tells the source what topic to read from
    agent.sources.kafkaSource.topic = final-test-1, final-test-2, final-test-3, final-test-4, final-test-5, 
    # Default value in flume
    agent.sources.kafkaSource.groupId = Flume
    # Tells the source what channel it will be sending the data to. 
    # We defined channel as the channel name up above
    agent.sources.kafkaSource.channels = channel
    
    #We are going to start the channel configuration
    agent.channels.channel.type=memory
    agent.channels.channel.capacity = 10000
    agent.channels.channel.transactionCapacity = 1000
    # The above configurations created a channel with type=memory meaning 
    # all the data is stored in memory rather than on disk. 
    # Then we specified how big to make it (capacity) and
    # how big each transaction can be.
    
    # Sink configurations start here
    agent.sinks.sinkToHdfs.type = hdfs
    # This defines where in hdfs we are going to be putting the data
    agent.sinks.sinkToHdfs.hdfs.path = hdfs://localhost:9000//kafka/%{topic}/%d-%m-%y
    agent.sinks.sinkToHdfs.hdfs.writeFormat = Text
    agent.sinks.sinkToHdfs.hdfs.useLocalTimeStamp = true
    agent.sinks.sinkToHdfs.hdfs.fileSuffix = .txt
    agent.sinks.sinkToHdfs.hdfs.filePrefix= sensor-data
    agent.sinks.sinkToHdfs.hdfs.callTimeout= 180000
    # How many seconds before it will start writing to HDFS
    agent.sinks.sinkToHdfs.rollInterval = 5
    # Configuring batch size
    agent.sources.kafkaSource.batchSize = 100
    # We could define a size but we left it at zero to not worry about it
    agent.sinks.sinkToHdfs.rollSize = 200
    # This configuration is for how many events to track before writing to hdfs.
    # We don't care about it, so we left it at 0.
    agent.sinks.sinkToHdfs.rollCount = 10
    agent.sinks.sinkToHdfs.hdfs.fileType = DataStream
    agent.sinks.sinkToHdfs.channel = channel
    